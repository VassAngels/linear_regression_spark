# Databricks notebook source
# MAGIC %md
# MAGIC #### Project Description - Predict Power Emission using Linear Regression
# MAGIC 
# MAGIC 0. Load in the dataset from UCI ML Repository https://archive.ics.uci.edu/ml/index.php. 
# MAGIC 0. Determine and evaluate a Baseline model
# MAGIC 0. Build and evaluate a Linear Regression Model using SparkML

# COMMAND ----------

# MAGIC %md ###1. Load Data
# MAGIC 
# MAGIC Import https://archive.ics.uci.edu/ml/datasets/combined+cycle+power+plant
# MAGIC 
# MAGIC 
# MAGIC Data Set Information:
# MAGIC 
# MAGIC The dataset contains 9568 data points collected from a Combined Cycle Power Plant over 6 years (2006-2011), when the power plant was set to work with full load. Features consist of hourly average ambient variables Temperature (AT), Ambient Pressure (AP), Relative Humidity (RH) and Exhaust Vacuum (V) to predict the net hourly electrical energy output (PE) of the plant.
# MAGIC A combined cycle power plant (CCPP) is composed of gas turbines (GT), steam turbines (ST) and heat recovery steam generators. In a CCPP, the electricity is generated by gas and steam turbines, which are combined in one cycle, and is transferred from one turbine to another. While the Vacuum is colected from and has effect on the Steam Turbine, he other three of the ambient variables effect the GT performance.
# MAGIC For comparability with our baseline studies, and to allow 5x2 fold statistical tests be carried out, we provide the data shuffled five times. For each shuffling 2-fold CV is carried out and the resulting 10 measurements are used for statistical testing.
# MAGIC We provide the data both in .ods and in .xlsx formats.
# MAGIC 
# MAGIC 
# MAGIC Attribute Information:
# MAGIC 
# MAGIC Features consist of hourly average ambient variables 
# MAGIC - Temperature (AT) in the range 1.81°C and 37.11°C,
# MAGIC - Ambient Pressure (AP) in the range 992.89-1033.30 milibar,
# MAGIC - Relative Humidity (RH) in the range 25.56% to 100.16%
# MAGIC - Exhaust Vacuum (V) in teh range 25.36-81.56 cm Hg
# MAGIC - Net hourly electrical energy output (PE) 420.26-495.76 MW
# MAGIC The averages are taken from various sensors located around the plant that record the ambient variables every second. The variables are given without normalization.

# COMMAND ----------

# File location and type
file_location = "/FileStore/tables/powerplant.csv"
file_type = "csv"

# CSV options
infer_schema = "true"
first_row_is_header = "true"
delimiter = ";"

# The applied options are for CSV files. For other file types, these will be ignored.
df = spark.read.format(file_type) \
  .option("inferSchema", infer_schema) \
  .option("header", first_row_is_header) \
  .option("sep", delimiter) \
  .load(file_location) \
  .na.drop()

display(df)

# COMMAND ----------

# MAGIC %md #####Examine distribution of target variable 'PE'

# COMMAND ----------

from pyspark.sql.functions import *
display(df.select('PE'))


# COMMAND ----------

from pyspark.sql.functions import *

print(df.select(mean('PE')).show())
median=df.approxQuantile('PE',[0.5],0)
print(f'Median: {median}')

# COMMAND ----------

# MAGIC %md ####2. Baseline Model

# COMMAND ----------

#Import dependencies
from pyspark.sql.functions import *

#Adding Average 
baseline = df.withColumn("averagePE", lit(454.0))

#Imputing Null Values
baseline = baseline.na.fill(454.0,'PE')

# COMMAND ----------

from pyspark.ml.evaluation import RegressionEvaluator

rmseRegressionEvaluator = RegressionEvaluator(labelCol='PE', metricName ='rmse', predictionCol='averagePE')
rmse=rmseRegressionEvaluator.evaluate(baseline)
# print(f'RMSE is: {rmse}')
r2RegressionEvaluator =RegressionEvaluator(labelCol='PE', metricName ='r2', predictionCol='averagePE')
r2=r2RegressionEvaluator.evaluate(baseline)
# print(f'R squared: {r2}')

# print(listItems)  
html = """
<body>
  <h2>Baseline Performance Metrics - RMSE and R2</h2>
  %s
</body>
""" % (f'RMSE: {rmse}     R2: {r2}')

displayHTML(html)

# COMMAND ----------

# MAGIC %md ###3. Linear Regression Model

# COMMAND ----------

# MAGIC %md #####Splitting Data into Train and Test

# COMMAND ----------

(trainDF, testDF) = df.randomSplit([.8, .2], seed=42)

# COMMAND ----------

# MAGIC %md #####Build and train model

# COMMAND ----------

from pyspark.ml.feature import VectorAssembler
from pyspark.ml.regression import LinearRegression

#Vectorising features columns in preparation for feeding into Linear Regression
#Define Vector Assembler
vecAssembler = VectorAssembler(inputCols = ["AT", "V", "AP", "RH"], outputCol = "features")

#Run train/test data through the assembler
vecTrainDF = vecAssembler.transform(trainDF)
vecTestDF = vecAssembler.transform(testDF)

#Create Linear Regression Model
lr = LinearRegression(featuresCol = "features", labelCol = "PE")

# Train Model
lrModel = lr.fit(vecTrainDF)

# COMMAND ----------

# MAGIC %md #####Make predictions using the test data 

# COMMAND ----------

predDF=lrModel.transform(vecTestDF)

# COMMAND ----------

display(predDF)

# COMMAND ----------

# MAGIC %md #####Evaluate the model 

# COMMAND ----------

from pyspark.ml.evaluation import RegressionEvaluator

rmseRegressionEvaluator = RegressionEvaluator(labelCol='PE', metricName ='rmse', predictionCol='prediction')
rmse=rmseRegressionEvaluator.evaluate(predDF)
print({rmse})
r2RegressionEvaluator =RegressionEvaluator(labelCol='PE', metricName ='r2', predictionCol='prediction')
r2=r2RegressionEvaluator.evaluate(predDF)
print({r2})



# print(listItems)  
html = """
<body>
  <h2>Linear Regression's Performance Metrics - RMSE and R2</h2>
  %s
</body>
""" % (f'RMSE: {rmse}     R2: {r2}')

displayHTML(html)

# COMMAND ----------

# MAGIC %md ####By comparing the performance metrics we can see the Linear Regression model performs way better than using the Baseline to predict PE as expected

# COMMAND ----------

# MAGIC %md-sandbox
# MAGIC &copy; 2019 Databricks, Inc. All rights reserved.<br/>
# MAGIC Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href="http://www.apache.org/">Apache Software Foundation</a>.<br/>
# MAGIC <br/>
# MAGIC <a href="https://databricks.com/privacy-policy">Privacy Policy</a> | <a href="https://databricks.com/terms-of-use">Terms of Use</a> | <a href="http://help.databricks.com/">Support</a>
